{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video import Video\n",
    "\n",
    "video_path = \"/home/sagarpatel/Desktop/ece496-capstone/train/sample/video.mp4\"\n",
    "transcript_path = \"/home/sagarpatel/Desktop/ece496-capstone/train/sample/transcript.vtt\"\n",
    "\n",
    "v = Video(video_path, transcript_path)\n",
    "v.align()\n",
    "v.generate_frames(\"sample\", swap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n",
      "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /home/sagarpatel/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\n",
      "All model checkpoint weights were used when initializing GeneralizedRCNN.\n",
      "\n",
      "All the weights of GeneralizedRCNN were initialized from the model checkpoint at unc-nlp/frcnn-vg-finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GeneralizedRCNN for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import itertools\n",
    "\n",
    "from model import Model\n",
    "from loss import loss_RA_MIL\n",
    "from detector import Detector\n",
    "from parser import parse\n",
    "\n",
    "detector = Detector()\n",
    "\n",
    "#Sample visualizer.\n",
    "#URL = \"/home/sagarpatel/Desktop/ece496-capstone/train/sample/9.png\"\n",
    "#detector.inference(URL, max_detections=3, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob.glob(\"/home/sagarpatel/Desktop/ece496-capstone/train/sample/*.png\"))\n",
    "candidates = [detector.inference(image, max_detections=5) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the steps in the video.\n",
    "steps = [step.text.strip().replace('.', '') for step in v.steps]\n",
    "\n",
    "# Find all of the bounding boxes for the detections and their features.\n",
    "boxes = torch.tensor([candidate[0].numpy() for candidate in candidates]).squeeze(1)\n",
    "features = torch.tensor([candidate[1].numpy() for candidate in candidates]).squeeze(1)\n",
    "\n",
    "# Find all of the entities in each of the sentences and their ordinal positions.\n",
    "entities, indices = parse(steps, max_step_length=10)\n",
    "\n",
    "# We need to add a dummy step that can be referred to as NULL.\n",
    "entities.append([\"unused0\"])\n",
    "indices.append([len(steps) * 10])\n",
    "steps.append(\"unused0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs=25, lr=0.001, batch_size=10, y=0.5):\n",
    "    '''\n",
    "    Training loop for the model.\n",
    "    '''\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Ouput losses.\n",
    "    train_loss = np.zeros(epochs)\n",
    "    \n",
    "    # Output accuracies.\n",
    "    train_accuracy = np.zeros(epochs)\n",
    "    \n",
    "    m_RR = None\n",
    "    m_VG = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for boxes, features, entities, indices in data:\n",
    "            # Zero out any gradients.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Run inference (forward pass).\n",
    "            _, RR, VG, _, loss_V, loss_E, loss_R, _, _, _  = model(steps, boxes, features, entities, indices)\n",
    "            \n",
    "            # Loss from alignment.\n",
    "            loss = loss_RA_MIL(y, loss_R, loss_E, loss_V)\n",
    "            print(loss)\n",
    "            \n",
    "            # Backpropagation (backward pass).\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update parameters.\n",
    "            optimizer.step()\n",
    "            \n",
    "            m_RR = RR\n",
    "            m_VG = VG\n",
    "            \n",
    "        # TODO: save loss and accuracy at each epoch, plot (and checkpoint).\n",
    "    return m_RR, m_VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52.8683, grad_fn=<SumBackward0>)\n",
      "tensor(428.3448, grad_fn=<SumBackward0>)\n",
      "tensor(79.1530, grad_fn=<SumBackward0>)\n",
      "tensor(149.3543, grad_fn=<SumBackward0>)\n",
      "tensor(165.3580, grad_fn=<SumBackward0>)\n",
      "tensor(22.3414, grad_fn=<SumBackward0>)\n",
      "tensor(23.1942, grad_fn=<SumBackward0>)\n",
      "tensor(61.6232, grad_fn=<SumBackward0>)\n",
      "tensor(22.9629, grad_fn=<SumBackward0>)\n",
      "tensor(7.7691, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Model(max_step_length=10)\n",
    "data = [(boxes, features, entities, indices)]\n",
    "\n",
    "RR, VG = train(model, data, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the tomatoes', 'a pan'],\n",
       " ['oil', 'the pan'],\n",
       " ['the bacon'],\n",
       " ['some mayonnaise', 'the bread'],\n",
       " ['a piece', 'lettuce', 'it'],\n",
       " ['the tomatoes', 'it'],\n",
       " ['some salt', 'it'],\n",
       " ['the bacon', 'the top'],\n",
       " ['the piece', 'bread', 'the top'],\n",
       " ['unused0']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grill the tomatoes in a pan',\n",
       " 'Add oil into the pan',\n",
       " 'Cook the bacon',\n",
       " 'Spread some mayonnaise onto the bread',\n",
       " 'Place a piece of lettuce onto it',\n",
       " 'Place the tomatoes over it',\n",
       " 'Sprinkle some salt and pepper onto it',\n",
       " 'Place the bacon at the top',\n",
       " 'Place the piece of bread at the top',\n",
       " 'unused0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tomatoes --> unused0\n",
      "a pan --> unused0\n",
      "oil --> unused0\n",
      "the pan --> unused0\n",
      "the bacon --> Add oil into the pan\n",
      "some mayonnaise --> unused0\n",
      "the bread --> unused0\n",
      "a piece --> Cook the bacon\n",
      "lettuce --> Cook the bacon\n",
      "it --> Cook the bacon\n",
      "the tomatoes --> Place a piece of lettuce onto it\n",
      "it --> Place a piece of lettuce onto it\n",
      "some salt --> unused0\n",
      "it --> Cook the bacon\n",
      "the bacon --> Sprinkle some salt and pepper onto it\n",
      "the top --> Cook the bacon\n",
      "the piece --> Sprinkle some salt and pepper onto it\n",
      "bread --> unused0\n",
      "the top --> Sprinkle some salt and pepper onto it\n",
      "unused0 --> unused0\n"
     ]
    }
   ],
   "source": [
    "entities_flat = [e for es in entities for e in es]\n",
    "RR_edges = RR.argmax(dim=1)\n",
    "\n",
    "for entity, edge in zip(entities_flat, RR_edges):\n",
    "    print('{} --> {}'.format(entity, steps[edge]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 0],\n",
       "        [3, 2, 0],\n",
       "        [3, 0, 0],\n",
       "        [2, 2, 0],\n",
       "        [1, 3, 0],\n",
       "        [1, 4, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 1, 0],\n",
       "        [4, 0, 0],\n",
       "        [2, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P\\left(d_{i j}=(l, k) \\mid E, A, B, R\\right)=\\operatorname{sigmoid}\\left(\\psi\\left(b_{l k}\\right)^{T} \\phi_{e}^{R}\\left(e_{i j}\\right)\\right)$$\n",
    "\n",
    "$$\\phi_{e}^{R}\\left(e_{i j}\\right)=w o r d Embd\\left(e_{i j}\\right)+\\phi_{a}^{R}\\left(a_{o}\\right)$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\max _{D_{l}} P\\left(D_{l} \\mid \\bar{G}_{l}, B_{l}\\right) &>\\max _{D_{l}} P\\left(D_{l} \\mid \\bar{G}_{l}, B_{m}\\right) \\\\\n",
    "\\max _{D_{l}} P\\left(D_{l} \\mid \\bar{G}_{l}, B_{l}\\right) &>\\max _{D_{n}} P\\left(D_{n} \\mid \\bar{G}_{n}, B_{l}\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "$$S_{l m}^{R}=\\sum_{j} \\max _{k}\\left\\langle\\phi_{e}^{R}\\left(e_{m j}\\right), \\psi_{b}\\left(b_{l k}\\right)\\right\\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\mathcal{L}_{R A-M I L}=\\sum_{l}[& \\sum_{m} \\gamma_{l m} \\cdot \\max \\left(0, S_{l m}^{R}-S_{l l}^{R}+\\Delta\\right) \\\\\n",
    "&\\left.+\\sum_{m} \\gamma_{m l} \\cdot \\max \\left(0, S_{m l}^{R}-S_{l l}^{R}+\\Delta\\right)\\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function terminology:\n",
    "    \n",
    "        l, m: step indices\n",
    "        j, k: entity indices\n",
    "        R: reference resolution edges\n",
    "\n",
    "        a_m: action step m\n",
    "        e_mj: j'th entity in step m\n",
    "        b_lk: bounding box for the k'th entity in step l\n",
    "\n",
    "        a(R, m, j): action referred to by the entity e_mj\n",
    "\n",
    "        ψ(l, k):\n",
    "            visual embedding of bounding box\n",
    "            -----------------------\n",
    "            ψ = VisualBERT_embedding(b_lk)\n",
    "\n",
    "        φA(m):\n",
    "            action embedding\n",
    "            -----------------------\n",
    "            φA = avg_j(VisualBERT_embedding(e_mj))\n",
    "\n",
    "        φE(R, m, j):\n",
    "            reference-aware entity embedding\n",
    "            -----------------------\n",
    "            φE = word_embedding(e_mj) + φA(a(R, m, j))\n",
    "\n",
    "        γ(l, m):\n",
    "            reference-based penalty\n",
    "            -----------------------\n",
    "            γ = 1     : if none of the entities in step m (a_m) have a reference to step l (a_l)\n",
    "            0 < γ < 1 : if atleast one entity in step m (a_m) has a reference to step l (a_l)\n",
    "\n",
    "        score(R, m, j, l, k):\n",
    "            alignment score between entity (e_mj) and bounding box (b_lk)\n",
    "            -----------------------\n",
    "            score = φE(R, m, j) · ψ(l, k)\n",
    "\n",
    "        S(R, l, m):\n",
    "            alignment score between steps (a_l and a_m)\n",
    "            -----------------------\n",
    "            S = sum_j(max_k(φE(R, m, j), ψ(l, k)))\n",
    "\n",
    "        Loss = sum_l\n",
    "               (\n",
    "                    sum_m [   γ(l, m) * max(0, S(R, l, m) - S(R, l, l))   ] \n",
    "                    sum_m [   γ(m, l) * max(0, S(R, m, l) - S(R, l, l))   ]\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
