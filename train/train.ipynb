{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import YouCookII\n",
    "from dataset import YouCookIICollate\n",
    "from torch.utils.data import DataLoader\n",
    "from loss import loss_RA_MIL\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from model import Model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, num_actions, batch_size, epochs=25, lr=0.001, y=0.5, MAX_DETECTIONS=20):\n",
    "    dataset = YouCookII(num_actions, \"/h/sagar/ece496-capstone/datasets/ycii\")\n",
    "    train_size = int(len(dataset) * (2/3))\n",
    "    valid_size = int(len(dataset) - train_size)\n",
    "    \n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "    \n",
    "    collate = YouCookIICollate(MAX_DETECTIONS=MAX_DETECTIONS)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, int(0.2*epochs), epochs)\n",
    "\n",
    "    train_loss = np.zeros(epochs)\n",
    "    valid_loss = np.zeros(epochs)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for data in train_dataloader:\n",
    "            _, bboxes_tensor, features_tensor, steps_list, entity_list, entity_count_list, _, _ = data\n",
    "            batch_size = len(data[0])\n",
    "            \n",
    "            # Zero out any gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Run inference (forward pass).            \n",
    "            loss_E, loss_V, loss_R, VG_dist1, VG_dist2, _, _, _, _, _ = model(batch_size, num_actions + 1, steps_list, features_tensor, bboxes_tensor, entity_count_list, entity_list)            \n",
    "            \n",
    "            # Loss from alignment.\n",
    "            loss_ = loss_RA_MIL(y, loss_R, loss_E, loss_V, VG_dist1, VG_dist2)\n",
    "\n",
    "            # Backpropagation (backward pass).\n",
    "            loss_.backward()\n",
    "\n",
    "            # Update parameters.\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss_\n",
    "            num_batches += 1\n",
    "        \n",
    "        #learning rate schedule\n",
    "        #update after each epoch\n",
    "        scheduler.step()\n",
    "        epoch_loss = epoch_loss / num_batches\n",
    "        \n",
    "        # Save loss and accuracy at each epoch, plot (and checkpoint).\n",
    "        train_loss[epoch] = epoch_loss\n",
    "        valid_loss[epoch] = get_validation_loss(num_actions, y, valid_dataloader)\n",
    "        \n",
    "        #after epoch completes\n",
    "        print(\"Epoch {} - Train Loss: {}, Validation Loss: {}\".format(epoch + 1, train_loss[epoch], valid_loss[epoch]))\n",
    "    \n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(valid_loss, label='valid loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    return train_loss, valid_loss\n",
    "\n",
    "def get_validation_loss(num_actions, y, valid_dataloader):\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in valid_dataloader:\n",
    "            _, bboxes_tensor, features_tensor, steps_list, entity_list, entity_count_list, _, _ = data\n",
    "            batch_size = len(data[0])\n",
    "\n",
    "            # Run inference (forward pass).\n",
    "            loss_E, loss_V, loss_R, VG_dist1, VG_dist2, _, _, _, _, _ = model(batch_size, num_actions + 1, steps_list, features_tensor, bboxes_tensor, entity_count_list, entity_list)\n",
    "\n",
    "\n",
    "            # Loss from alignment.\n",
    "            loss_ = loss_RA_MIL(y, loss_R, loss_E, loss_V, VG_dist1, VG_dist2)\n",
    "            \n",
    "            epoch_loss += loss_\n",
    "            num_batches += 1\n",
    "            \n",
    "    epoch_loss = epoch_loss / num_batches\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-standard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(device, MAX_DETECTIONS=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fi import eval_all_dataset\n",
    "eval_all_dataset(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, valid_loss = train(model, 8, 2, epochs=50, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizer import inference\n",
    "\n",
    "YCII = \"/h/sagar/ece496-capstone/datasets/ycii\"\n",
    "FI = \"/h/sagar/ece496-capstone/datasets/fi\"\n",
    "\n",
    "VG, RR = inference(model, 10, 1, FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading weights.\n",
    "\n",
    "SAVE = False\n",
    "LOAD = False\n",
    "\n",
    "if SAVE:\n",
    "    torch.save(model.state_dict(), \"/h/sagar/ece496-capstone/weights/weights-epochs=50,bs=2,lr=1e-3,a=8\")\n",
    "    \n",
    "if LOAD:\n",
    "    model.load_state_dict(torch.load(\"/h/sagar/ece496-capstone/weights/weights-epochs=50,bs=2,lr=1e-3,a=8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules.\n",
    "\n",
    "import importlib\n",
    "import visualizer\n",
    "\n",
    "importlib.reload(visualizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
