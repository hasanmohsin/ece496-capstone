{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fossil-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import YouCookII\n",
    "from dataset import YouCookIICollate\n",
    "from torch.utils.data import DataLoader\n",
    "from loss import *\n",
    "from accuracy import *\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from model import Model\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, num_actions, batch_size, epochs=25, lr=0.001, MAX_DETECTIONS=20):\n",
    "    dataset = YouCookII(num_actions, \"/h/sagar/ece496-capstone/datasets/ycii\")\n",
    "    train_size = int(len(dataset) * (2/3))\n",
    "    valid_size = int(len(dataset) - train_size)\n",
    "    \n",
    "    print(\"Training Dataset Size: {}, Validation Dataset Size: {}\".format(train_size, valid_size))\n",
    "    \n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "    \n",
    "    collate = YouCookIICollate(MAX_DETECTIONS=MAX_DETECTIONS)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate, drop_last=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate, drop_last=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, int(0.2*epochs), epochs)\n",
    "\n",
    "    train_loss = np.zeros(epochs)\n",
    "    valid_loss = np.zeros(epochs)\n",
    "    \n",
    "    train_accuracy = np.zeros(epochs)\n",
    "    valid_accuracy = np.zeros(epochs)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        epoch_loss = 0.\n",
    "        num_batches = 0\n",
    "        \n",
    "        total = 0\n",
    "        correct = 0\n",
    "                \n",
    "        for data in train_dataloader:\n",
    "            _, bboxes, features, steps, entities, entity_count, _, _ = data\n",
    "            \n",
    "            # Zero out any gradients.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Run inference (forward pass).\n",
    "            loss_data, VG, RR = model(batch_size, num_actions, steps, features, bboxes, entities, entity_count)\n",
    "            \n",
    "            # Loss from alignment.\n",
    "            loss_ = compute_loss_batched(loss_data)\n",
    "\n",
    "            # Backpropagation (backward pass).\n",
    "            loss_.backward()\n",
    "\n",
    "            # Update parameters.\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss_\n",
    "            num_batches += 1\n",
    "            \n",
    "        # Scheduler update.\n",
    "        scheduler.step()\n",
    "        epoch_loss = epoch_loss / (num_batches * batch_size)\n",
    "        \n",
    "        # Save loss and accuracy at each epoch and plot.\n",
    "        train_loss[epoch] = float(epoch_loss)\n",
    "        train_accuracy[epoch] = get_alignment_accuracy(model, train_dataloader, batch_size, num_actions) \n",
    "        \n",
    "        valid_loss[epoch] = get_alignment_loss(model, valid_dataloader, batch_size, num_actions)\n",
    "        valid_accuracy[epoch] = get_alignment_accuracy(model, valid_dataloader, batch_size, num_actions)\n",
    "\n",
    "        print(\"Epoch {} - Train Loss: {:.2f}, Validation Loss: {:.2f}, Train Accuracy: {:.2f}, Validation Accuracy: {:.2f}\"\n",
    "              .format(epoch + 1, train_loss[epoch], valid_loss[epoch], train_accuracy[epoch], valid_accuracy[epoch]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='train loss')\n",
    "    plt.plot(valid_loss, label='valid loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_accuracy, label='train accuracy')\n",
    "    plt.plot(valid_accuracy, label='valid accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "    return train_loss, valid_loss, train_accuracy, valid_accuracy, VG, loss_data, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "australian-standard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Size: 38, Validation Dataset Size: 19\n",
      "Epoch 1 - Train Loss: 1225.46, Validation Loss: 1132.88, Train Accuracy: 0.51, Validation Accuracy: 0.50\n",
      "Epoch 2 - Train Loss: 1219.69, Validation Loss: 1162.51, Train Accuracy: 0.50, Validation Accuracy: 0.49\n",
      "Epoch 3 - Train Loss: 1216.06, Validation Loss: 1158.76, Train Accuracy: 0.48, Validation Accuracy: 0.50\n",
      "Epoch 4 - Train Loss: 1230.95, Validation Loss: 1144.92, Train Accuracy: 0.50, Validation Accuracy: 0.51\n",
      "Epoch 5 - Train Loss: 1200.11, Validation Loss: 1160.29, Train Accuracy: 0.49, Validation Accuracy: 0.49\n",
      "Epoch 6 - Train Loss: 1215.41, Validation Loss: 1188.60, Train Accuracy: 0.49, Validation Accuracy: 0.52\n",
      "Epoch 7 - Train Loss: 1222.61, Validation Loss: 1161.85, Train Accuracy: 0.49, Validation Accuracy: 0.50\n",
      "Epoch 8 - Train Loss: 1218.94, Validation Loss: 1151.75, Train Accuracy: 0.50, Validation Accuracy: 0.48\n",
      "Epoch 9 - Train Loss: 1219.54, Validation Loss: 1173.54, Train Accuracy: 0.49, Validation Accuracy: 0.52\n",
      "Epoch 10 - Train Loss: 1184.44, Validation Loss: 1141.74, Train Accuracy: 0.50, Validation Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Trainer.\n",
    "\n",
    "train_loss, valid_loss, train_accuracy, valid_accuracy, VG, loss_data, data = train(model, 8, 4, epochs=500, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation.\n",
    "\n",
    "from eval_fi import eval_all_dataset\n",
    "eval_all_dataset(model, path=\"/h/sagar/ece496-capstone/datasets/fi_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizer.\n",
    "\n",
    "from visualizer import inference\n",
    "\n",
    "YCII = \"/h/sagar/ece496-capstone/datasets/ycii\"\n",
    "FI = \"/h/sagar/ece496-capstone/datasets/fi\"\n",
    "\n",
    "VG, RR = inference(model, 27, 0, FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading weights.\n",
    "\n",
    "SAVE = False\n",
    "LOAD = True\n",
    "\n",
    "if SAVE:\n",
    "    torch.save(model.state_dict(), \"/h/sagar/ece496-capstone/weights/t1\")\n",
    "    \n",
    "if LOAD:\n",
    "    model.load_state_dict(torch.load(\"/h/sagar/ece496-capstone/weights/t1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules.\n",
    "\n",
    "import importlib\n",
    "import visualizer\n",
    "import eval_fi\n",
    "import model as mdl\n",
    "import loss\n",
    "\n",
    "importlib.reload(visualizer)\n",
    "importlib.reload(eval_fi)\n",
    "importlib.reload(mdl)\n",
    "importlib.reload(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-perspective",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
