{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "patient-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "tropical-yacht",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4185)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 0.5\n",
    "\n",
    "# 5 steps with each having 2 entities.\n",
    "E = torch.rand(5, 2)\n",
    "V = torch.rand(5, 2)\n",
    "R = torch.round(torch.rand(5, 5))\n",
    "\n",
    "loss_RAVG(y, R, E, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "neither-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify function to work with batches and non-scalar embeddings.\n",
    "\n",
    "def loss_RAVG(y, R, E, V):\n",
    "    '''\n",
    "    Custom loss function for reference-aware visual grounding. This function must\n",
    "    use PyTorch functions for any parameters that are to be trained. Some of the\n",
    "    embeddings have been modified to match the VisualBERT model.\n",
    "    \n",
    "    The outputs of the VG extension are the alignment scores between the bounding\n",
    "    box proposals and entities for that particular step. The size of this matrix\n",
    "    is E x P, where E is the number of entities and P is the number of proposals.\n",
    "    \n",
    "    Source: http://vision.stanford.edu/pdf/huang-buch-2018cvpr.\n",
    "    \n",
    "    Input:\n",
    "        y: alignment penalty (hyperparameter)\n",
    "    \n",
    "        R:\n",
    "            references\n",
    "            -----------------------\n",
    "            The size of the matrix is M x M. M is the number of steps.\n",
    "            \n",
    "            R_lj contains a 1 if there is any backward reference between a_l and a_j.\n",
    "            \n",
    "        V:\n",
    "            visual embeddings\n",
    "            -----------------------\n",
    "            The size of the matrix is M x J. M is the number of steps and J is the maximum\n",
    "            number of entities across all of the steps.\n",
    "            \n",
    "            V_mj contains the visual embedding that corresponds to e_mj entity. This is the\n",
    "            b_mj bounding box (bounding box with highest alignment score). Since each the\n",
    "            steps may have a different number of entities, there may be some padding of 1 \n",
    "            required.\n",
    "            \n",
    "            Note: for now, we assume that the embedding is a scalar.\n",
    "            \n",
    "        E:\n",
    "            reference aware entity embeddings\n",
    "            -----------------------\n",
    "            The size of the matrix is M x J. E_mj contains the reference aware entity embedding\n",
    "            of e_mj. Since each the steps may have a different number of entities, there may be\n",
    "            some padding of -inf required.\n",
    "            \n",
    "            Note: for now, we assume that the embedding is a scalar.\n",
    "    '''\n",
    "    \n",
    "    M = E.shape[0]\n",
    "    J = E.shape[1]\n",
    "\n",
    "    # Compute the outer product between E and V. This essentially calculates\n",
    "    # all possible alignment scores across the entire video. scores_lmjk is\n",
    "    # the alignment score of e_mj and b_lk (same as equation). The size of\n",
    "    # the matrix is M x J x M x J.\n",
    "    #\n",
    "    # Ref: stackoverflow.com/questions/24839481/python-matrix-outer-product\n",
    "    #\n",
    "    # Note that the alignment score for the padding matrices will be -inf due\n",
    "    # to the way they're configured (1 * -inf).\n",
    "    scores = torch.einsum('mj, lk -> lmjk', E, V)\n",
    "\n",
    "    # The best alignment score between e_mj and b_lk (over all k).\n",
    "    max_k_align = scores.max(3)[0]\n",
    "\n",
    "    # Sum all of the best alignment scores from e_mj (over all j).\n",
    "    S_lm = max_k_align.sum(2)\n",
    "\n",
    "    # Find the transposed version.\n",
    "    S_ml = S_lm.transpose(0, 1)\n",
    "\n",
    "    # Self alignment scores.\n",
    "    S_ll = S_lm[0].repeat(M, 1)\n",
    "\n",
    "    # Compute reference based penalty. 1 if none of the entities in e_m refer\n",
    "    # to a_l, constant (hyperparameter) otherwise. We can use R since it has\n",
    "    # the mappings between each of the actions. This is a M x M matrix.\n",
    "    Y_lm = R * y\n",
    "    Y_ml = Y_lm.transpose(0, 1)\n",
    "\n",
    "    # Zero matrix.\n",
    "    zero = torch.zeros(M, M)\n",
    "\n",
    "    # S_ll needs to have the rows filled with diagonal values. Note that unsqueeze(1)\n",
    "    # for a vector is the same as transposing it.\n",
    "    S_ll = S_lm.diagonal().unsqueeze(1).repeat(1, M)\n",
    "\n",
    "    # Vectorization magic.\n",
    "    loss = (Y_lm * torch.max(zero, S_lm - S_ll) + Y_ml * torch.max(zero, S_ml - S_ll)).sum()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dirty-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, epochs=25, lr=0.001, batch_size=10, y=0.5):\n",
    "    '''\n",
    "    Training loop for the model (VisualBERT + extensions).\n",
    "    '''\n",
    "    \n",
    "    optimizer = torch.optim.adam(model.parameters, lr=lr)\n",
    "    \n",
    "    # Ouput losses.\n",
    "    train_loss = np.zeros(epochs)\n",
    "    valid_loss = np.zeros(epochs)\n",
    "    \n",
    "    # Output accuracies.\n",
    "    train_accuracy = np.zeroes(epochs)\n",
    "    valid_accuracy = np.zeroes(epochs)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for videos, transcripts in iter(train_loader):\n",
    "            # Note that there is no target since supervision is \n",
    "            # provided only through the alignment.\n",
    "            \n",
    "            # Zero out any gradients.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Run inference (forward pass).\n",
    "            outputs = model(videos, transcripts)\n",
    "            \n",
    "            # TODO: Generate R, E, V.\n",
    "            m_loss_RAVG = loss_RAVG(R, E, V)\n",
    "            \n",
    "            # TODO: Loss for GARR.\n",
    "            m_loss_GARR = 0\n",
    "            \n",
    "            loss = m_loss_RAVG + m_loss_GARR\n",
    "            \n",
    "            # Backpropagation (backward pass).\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update parameters.\n",
    "            optimizer.step()\n",
    "            \n",
    "        # TODO: save loss and accuracy at each epoch, plot (and checkpoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-computer",
   "metadata": {},
   "source": [
    "$$P\\left(d_{i j}=(l, k) \\mid E, A, B, R\\right)=\\operatorname{sigmoid}\\left(\\psi\\left(b_{l k}\\right)^{T} \\phi_{e}^{R}\\left(e_{i j}\\right)\\right)$$\n",
    "\n",
    "$$\\phi_{e}^{R}\\left(e_{i j}\\right)=w o r d Embd\\left(e_{i j}\\right)+\\phi_{a}^{R}\\left(a_{o}\\right)$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\max _{D_{l}} P\\left(D_{l} \\mid \\bar{G}_{l}, B_{l}\\right) &>\\max _{D_{l}} P\\left(D_{l} \\mid \\bar{G}_{l}, B_{m}\\right) \\\\\n",
    "\\max _{D_{l}} P\\left(D_{l} \\mid \\bar{G}_{l}, B_{l}\\right) &>\\max _{D_{n}} P\\left(D_{n} \\mid \\bar{G}_{n}, B_{l}\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "$$S_{l m}^{R}=\\sum_{j} \\max _{k}\\left\\langle\\phi_{e}^{R}\\left(e_{m j}\\right), \\psi_{b}\\left(b_{l k}\\right)\\right\\rangle$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-format",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\mathcal{L}_{R A-M I L}=\\sum_{l}[& \\sum_{m} \\gamma_{l m} \\cdot \\max \\left(0, S_{l m}^{R}-S_{l l}^{R}+\\Delta\\right) \\\\\n",
    "&\\left.+\\sum_{m} \\gamma_{m l} \\cdot \\max \\left(0, S_{m l}^{R}-S_{l l}^{R}+\\Delta\\right)\\right]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-separate",
   "metadata": {},
   "source": [
    "Loss function terminology:\n",
    "    \n",
    "        l, m: step indices\n",
    "        j, k: entity indices\n",
    "        R: reference resolution edges\n",
    "\n",
    "        a_m: action step m\n",
    "        e_mj: j'th entity in step m\n",
    "        b_lk: bounding box for the k'th entity in step l\n",
    "\n",
    "        a(R, m, j): action referred to by the entity e_mj\n",
    "\n",
    "        ψ(l, k):\n",
    "            visual embedding of bounding box\n",
    "            -----------------------\n",
    "            ψ = VisualBERT_embedding(b_lk)\n",
    "\n",
    "        φA(m):\n",
    "            action embedding\n",
    "            -----------------------\n",
    "            φA = avg_j(VisualBERT_embedding(e_mj))\n",
    "\n",
    "        φE(R, m, j):\n",
    "            reference-aware entity embedding\n",
    "            -----------------------\n",
    "            φE = word_embedding(e_mj) + φA(a(R, m, j))\n",
    "\n",
    "        γ(l, m):\n",
    "            reference-based penalty\n",
    "            -----------------------\n",
    "            γ = 1     : if none of the entities in step m (a_m) have a reference to step l (a_l)\n",
    "            0 < γ < 1 : if atleast one entity in step m (a_m) has a reference to step l (a_l)\n",
    "\n",
    "        score(R, m, j, l, k):\n",
    "            alignment score between entity (e_mj) and bounding box (b_lk)\n",
    "            -----------------------\n",
    "            score = φE(R, m, j) · ψ(l, k)\n",
    "\n",
    "        S(R, l, m):\n",
    "            alignment score between steps (a_l and a_m)\n",
    "            -----------------------\n",
    "            S = sum_j(max_k(φE(R, m, j), ψ(l, k)))\n",
    "\n",
    "        Loss = sum_l\n",
    "               (\n",
    "                    sum_m [   γ(l, m) * max(0, S(R, l, m) - S(R, l, l))   ] \n",
    "                    sum_m [   γ(m, l) * max(0, S(R, m, l) - S(R, l, l))   ]\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
