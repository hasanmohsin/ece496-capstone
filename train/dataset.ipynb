{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from detector import Detector\n",
    "from parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path='output.json'):\n",
    "    \"\"\"\n",
    "    Check for valid JSON format and read content\n",
    "    path: path to JSON file\n",
    "    \"\"\"\n",
    "    file = open(path)\n",
    "    line = file.read().replace('\\n', ' ')\n",
    "    file.close()\n",
    "    try:\n",
    "        parsed_json = json.loads(line)\n",
    "    except:\n",
    "        assert False, 'Invalid JSON'\n",
    "    return parsed_json\n",
    "\n",
    "def get_vid_ext(vid_id, video_dir):\n",
    "    \"\"\"\n",
    "    Returns video file extension\n",
    "    vid_id: video id\n",
    "    video_dir: directory path to video files\n",
    "    \"\"\"\n",
    "    vid_prefix = os.path.join(video_dir, vid_id)\n",
    "    if os.path.exists(vid_prefix+'.mp4'):\n",
    "        return '.mp4'\n",
    "    elif os.path.exists(vid_prefix+'.mkv'):\n",
    "        return '.mkv'\n",
    "    elif os.path.exists(vid_prefix+'.webm'):\n",
    "        return '.webm'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(vid_id, video_dir):\n",
    "    \"\"\"\n",
    "    Download video\n",
    "    vid_id: video id\n",
    "    video_dir: directory path to video files\n",
    "    \"\"\"\n",
    "    # download the video\n",
    "    vid_url = 'www.youtube.com/watch?v='+vid_id\n",
    "    vid_prefix = os.path.join(video_dir, vid_id) \n",
    "    os.system(' '.join((\"youtube-dl -o\", vid_prefix, vid_url)))\n",
    "\n",
    "\n",
    "def sample_frames(vid_id, video_dir, frame_dir, fps=5):\n",
    "    \"\"\"\n",
    "    Sample video into frames at fixed fps\n",
    "    vid_id: video id\n",
    "    video_dir: directory path to video files\n",
    "    frame_dir: directory path to video frames\n",
    "    fps: fps for frame extraction\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(os.path.join(frame_dir, vid_id)):\n",
    "        os.mkdir(os.path.join(frame_dir, vid_id))\n",
    "    vid_ext = get_vid_ext(vid_id, video_dir)\n",
    "    ff_command = 'ffmpeg -i {}/{}{} -y -an -qscale 0 -vf fps={} {}/{}/%06d.jpg'.format(video_dir, vid_id, vid_ext, fps, frame_dir, vid_id)\n",
    "    os.system(ff_command)\n",
    "\n",
    "\n",
    "def remove_video(vid_id, video_dir):\n",
    "    \"\"\"\n",
    "    Delete video\n",
    "    vid_id: video id\n",
    "    video_dir: directory path to video files\n",
    "    \"\"\"\n",
    "    vid_prefix = os.path.join(video_dir, vid_id)\n",
    "    vid_ext = get_vid_ext(vid_id, video_dir)\n",
    "    os.remove(vid_prefix+vid_ext)\n",
    "\n",
    "\n",
    "def select_frames(actions, vid_id, num_frames_per_step):\n",
    "    \"\"\"\n",
    "    Returns representative frames for actions\n",
    "    actions: list of action annotations from YCII annotations\n",
    "    vid_id: video id\n",
    "    num_frames_per_step: number of frames per action step\n",
    "    Returns required_frames: set contataining names of representative frames\n",
    "    \"\"\"\n",
    "    required_frames = set()\n",
    "    for action in actions:\n",
    "        action_start = action['segment'][0]\n",
    "        action_end = action['segment'][1]\n",
    "        action_delta = (action_end - action_start) / (num_frames_per_step + 1)    # need num_frames_per_step+1 intervals for num_frames_per_step inner frames\n",
    "        for i in range(num_frames_per_step):\n",
    "            frame_time = action_start + action_delta * (i+1)    # in seconds\n",
    "            frame_id = int( frame_time*(num_frames_per_step + 1) )\n",
    "            frame_name = '{}.jpg'.format(str(frame_id).zfill(6))\n",
    "            required_frames.add(frame_name)\n",
    "    return required_frames\n",
    "\n",
    "\n",
    "def remove_frames(vid_id, frame_dir, required_frames):\n",
    "    \"\"\"\n",
    "    Remove unused frames\n",
    "    vid_id: video id\n",
    "    frame_dir: directory path to video frames\n",
    "    required_frames: set contataining names of representative frames\n",
    "    \"\"\"\n",
    "    if os.path.isdir(os.path.join(frame_dir, vid_id)):\n",
    "        curr_frames = os.listdir(os.path.join(frame_dir, vid_id))\n",
    "        for frame in curr_frames:\n",
    "            if frame not in required_frames:\n",
    "                os.remove(os.path.join(frame_dir, vid_id, frame))\n",
    "\n",
    "\n",
    "def get_actions(actions):\n",
    "    \"\"\"\n",
    "    Returns list of actions text for video\n",
    "    actions: list of action annotations from YCII annotations\n",
    "    Returns actions_text: list of actions text for video\n",
    "    \"\"\"\n",
    "    actions_text = []\n",
    "    for action in actions:\n",
    "        actions_text.append(action['sentence'])\n",
    "    return actions_text\n",
    "\n",
    "\n",
    "def pickle_data(data, pickles_dir, vid_id, fname):\n",
    "    \"\"\"\n",
    "    Pickle data into bytestreams\n",
    "    data: data to be pickled\n",
    "    pickles_dir: directory path to pickled data\n",
    "    vid_id: video id\n",
    "    fname: name of pickled file\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(os.path.join(pickles_dir, vid_id)):\n",
    "        os.mkdir(os.path.join(pickles_dir, vid_id))\n",
    "    pickle_out = open(os.path.join(pickles_dir, vid_id, fname+'.pickle'), 'wb')\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "\n",
    "def depickle_data(pickles_dir, vid_id, fname):\n",
    "    \"\"\"\n",
    "    Depickle data from bytestreams\n",
    "    pickles_dir: directory path to pickled data\n",
    "    vid_id: video id\n",
    "    fname: name of pickled file\n",
    "    \"\"\"\n",
    "    pickle_path = os.path.join(pickles_dir, vid_id, fname+'.pickle')\n",
    "    if os.path.exists(pickle_path):\n",
    "        pickle_in = open(pickle_path, 'rb')\n",
    "        candidates = pickle.load(pickle_in)\n",
    "        return candidates\n",
    "    return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_root='/h/mkhan/ece496-capstone/datasets', num_frames_per_step=4):\n",
    "    \"\"\"\n",
    "    Download and prepare dataset files\n",
    "    dataset_root: directory path to dataset base\n",
    "    num_frames_per_step: number of frames per action step\n",
    "    \"\"\"\n",
    "\n",
    "    annotations = read_json(os.path.join(dataset_root, 'annotations', 'ycii_annotations_trainval.json'))['database']\n",
    "    \n",
    "    videos_root = os.path.join(dataset_root, 'ycii_videos')\n",
    "    if not os.path.isdir(videos_root):\n",
    "        os.mkdir(videos_root)\n",
    "    frames_root = os.path.join(dataset_root, 'ycii_frames')\n",
    "    if not os.path.isdir(frames_root):\n",
    "        os.mkdir(frames_root)\n",
    "    pickles_root = os.path.join(dataset_root, 'ycii_pickles')\n",
    "    if not os.path.isdir(pickles_root):\n",
    "        os.mkdir(pickles_root)\n",
    "\n",
    "    missing_vid_list = []\n",
    "\n",
    "    detector = Detector()\n",
    "    \n",
    "    with open(os.path.join(dataset_root, 'vid_list', 'vid_list_ycii_val_short.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            rcp_type,vid_id = line.replace('\\n','').split('/')\n",
    "            print('[INFO] Processing video {}'.format(vid_id))\n",
    "            \n",
    "            # download the video\n",
    "#             download_video(vid_id, videos_root)\n",
    "            vid_url = 'www.youtube.com/watch?v='+vid_id\n",
    "            vid_prefix = os.path.join(videos_root, vid_id) \n",
    "            os.system(' '.join((\"youtube-dl -o\", vid_prefix, vid_url)))\n",
    "\n",
    "            # check if the video is available\n",
    "            if os.path.exists(vid_prefix+'.mp4') or os.path.exists(vid_prefix+'.mkv') or os.path.exists(vid_prefix+'.webm'):\n",
    "                print('[INFO] Downloaded video {}'.format(vid_id))\n",
    "            else:\n",
    "                missing_vid_list.append(line)\n",
    "                print('[INFO] Cannot download video {}'.format(vid_id))\n",
    "                continue\n",
    "\n",
    "            # sample frames at fixed fps\n",
    "            sample_frames(vid_id, videos_root, frames_root, fps=5)\n",
    "            print('[INFO] Sampled frames for video {}'.format(vid_id))\n",
    "\n",
    "            # remove sampled video file (optional)\n",
    "            remove_video(vid_id, videos_root)\n",
    "            print('[INFO] Removed video {}'.format(vid_id))\n",
    "            \n",
    "            # select representative frames for actions\n",
    "            actions = annotations[vid_id]['annotations']\n",
    "            selected_frames = select_frames(actions, vid_id, num_frames_per_step)\n",
    "            print('[INFO] Selected frames for video {}'.format(vid_id))\n",
    "\n",
    "            # remove unsued frames\n",
    "            remove_frames(vid_id, frames_root, selected_frames)\n",
    "            print('[INFO] Removed unused frames for video {}'.format(vid_id))\n",
    "\n",
    "            # get candidates for images\n",
    "            frames = sorted(glob.glob(os.path.join(frames_root, vid_id, '*.*')))\n",
    "            candidates = [detector.inference(frame, max_detections=5) for frame in frames]\n",
    "            print('[INFO] Extracted candidates for video {}'.format(vid_id))\n",
    "\n",
    "            # save pickeled files for candidates\n",
    "            pickle_data(candidates, pickles_root, vid_id, 'candidates')\n",
    "            print('[INFO] Saved candidates for video {}'.format(vid_id))\n",
    "            \n",
    "            # get annotations list\n",
    "            actions_list = get_actions(actions)\n",
    "            print('[INFO] Extracted actions for video {}'.format(vid_id))\n",
    "            \n",
    "            # save pickled files for annotations list\n",
    "            pickle_data(actions_list, pickles_root, vid_id, 'actions')\n",
    "            print('[INFO] Saved candidates for video {}'.format(vid_id))\n",
    "\n",
    "\n",
    "    # write the missing videos to file\n",
    "    missing_vid = open(os.path.join(dataset_root, 'vid_list', 'missing_videos.txt'), 'w')\n",
    "    for line in missing_vid_list:\n",
    "        missing_vid.write(line)\n",
    "\n",
    "    # sanitize and remove the intermediate files\n",
    "    # os.system(\"find {} -name '*.part*' -delete\".format(dataset_root))\n",
    "    os.system(\"find {} -name '*.f*' -delete\".format(dataset_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_root='/h/mkhan/ece496-capstone/datasets'):\n",
    "    \"\"\"\n",
    "    Load dataset values from saved files\n",
    "    dataset_root: directory path to dataset base\n",
    "    \"\"\"\n",
    "    pickles_root = os.path.join(dataset_root, 'ycii_pickles')\n",
    "    \n",
    "    all_candidates = []\n",
    "    all_actions = []\n",
    "    with open(os.path.join(dataset_root, 'vid_list', 'vid_list_ycii_val_short.txt')) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            rcp_type,vid_id = line.replace('\\n','').split('/')\n",
    "            print('[INFO] Loading data for video {}'.format(vid_id))\n",
    "            \n",
    "            # load candidates data\n",
    "            candidates = depickle_data(pickles_root, vid_id, 'candidates')\n",
    "            if candidates:\n",
    "                all_candidates.extend(candidates)\n",
    "                print('[INFO] Loaded candidates for video {}'.format(vid_id))\n",
    "            else:\n",
    "                print('[INFO] Cannot load candidates for video {}'.format(vid_id))\n",
    "\n",
    "            # load actions data\n",
    "            actions = depickle_data(pickles_root, vid_id, 'actions')\n",
    "            if actions:\n",
    "                all_actions.append(actions)\n",
    "                print('[INFO] Loaded actions for video {}'.format(vid_id))\n",
    "            else:\n",
    "                print('[INFO] Cannot load actions for video {}'.format(vid_id))\n",
    "\n",
    "    return all_candidates, all_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n",
      "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /h/mkhan/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\n",
      "All model checkpoint weights were used when initializing GeneralizedRCNN.\n",
      "\n",
      "All the weights of GeneralizedRCNN were initialized from the model checkpoint at unc-nlp/frcnn-vg-finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GeneralizedRCNN for predictions without further training.\n",
      "[INFO] Processing video fn9anlEL4FI\n",
      "[INFO] Extracted actions for video fn9anlEL4FI\n",
      "[INFO] Saved candidates for video fn9anlEL4FI\n"
     ]
    }
   ],
   "source": [
    "# USAGE: Run this just once to prepare and save data on disk\n",
    "prepare_dataset(dataset_root='/h/mkhan/ece496-capstone/datasets', num_frames_per_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data for video fn9anlEL4FI\n",
      "[INFO] Loaded candidates for video fn9anlEL4FI\n",
      "[INFO] Loaded actions for video fn9anlEL4FI\n"
     ]
    }
   ],
   "source": [
    "# USAGE: Run this to load all candidate and actions data from disk\n",
    "# TODO: Need to pass all_actions through parser.parse and tokenize text data\n",
    "all_candidates, all_actions = load_dataset(dataset_root='/h/mkhan/ece496-capstone/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Don't execute the cells below, they are rough code for testing out stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = read_json(os.path.join('/h/mkhan/ece496-capstone/datasets', 'annotations', 'ycii_annotations_trainval.json'))['database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = annotations['fn9anlEL4FI']['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for item in annotations:\n",
    "    if annotations[item]['subset']=='validation':\n",
    "        print(item)\n",
    "#         print(annotations[item])\n",
    "        print(annotations[item]['duration'])\n",
    "#         print(annotations[item]['annotations'])\n",
    "        segments = annotations[item]['annotations']\n",
    "        for segment in segments:\n",
    "            print(segment)\n",
    "#             start = segment['segment'][0]\n",
    "            end = segment['segment'][1]\n",
    "#             print(str(start) + \" \" + str(end))\n",
    "        \n",
    "        print(end)\n",
    "\n",
    "        i += 1\n",
    "        if i==3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
